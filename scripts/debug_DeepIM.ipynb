{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Deep Iterative Matching Network\n",
    "# Licensed under The Apache-2.0 License [see LICENSE for details]\n",
    "# Written by Yi Li\n",
    "# --------------------------------------------------------\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "\n",
    "#sys.path.insert(0, os.getcwd())\n",
    "#sys.path.append(os.path.join(os.getcwd() + '/src'))\n",
    "sys.path.append('/home/jonfrey/mx-DeepIM')\n",
    "\n",
    "from lib.utils.projection import se3_inverse, se3_mul, backproject_camera\n",
    "from time import time\n",
    "\n",
    "\n",
    "def calc_flow(depth_src, pose_src, pose_tgt, K, depth_tgt, thresh=3e-3, standard_rep=False):\n",
    "    \"\"\"\n",
    "    project the points in source corrd to target corrd\n",
    "    :param standard_rep:\n",
    "    :param depth_src: depth image of source(m)\n",
    "    :param pose_src: pose matrix of soucre, [R|T], 3x4\n",
    "    :param depth_tgt: depth image of target\n",
    "    :param pose_tgt: pose matrix of target, [R|T], 3x4\n",
    "    :param K: intrinsic_matrix\n",
    "    :param depth_tgt: depth image of target(m)\n",
    "    :return: visible: whether points in source can be viewed in target\n",
    "    :return: flow: flow from source to target\n",
    "    \"\"\"\n",
    "    height = depth_src.shape[0]\n",
    "    width = depth_src.shape[1]\n",
    "    visible = np.zeros(depth_src.shape[:2]).flatten()\n",
    "    X = backproject_camera(depth_src, intrinsic_matrix=K)\n",
    "    transform = np.matmul(K, se3_mul(pose_tgt, se3_inverse(pose_src)))\n",
    "    Xp = np.matmul(transform, np.append(X, np.ones([1, X.shape[1]], dtype=np.float32), axis=0))\n",
    "\n",
    "    pz = Xp[2] + 1e-15\n",
    "    pw = Xp[0] / pz\n",
    "    ph = Xp[1] / pz\n",
    "\n",
    "    valid_points = np.where(depth_src.flatten() != 0)[0]\n",
    "    depth_proj_valid = pz[valid_points]\n",
    "    pw_valid_raw = np.round(pw[valid_points]).astype(int)\n",
    "    pw_valid = np.minimum(np.maximum(pw_valid_raw, 0), width - 1)\n",
    "    ph_valid_raw = np.round(ph[valid_points]).astype(int)\n",
    "    ph_valid = np.minimum(np.maximum(ph_valid_raw, 0), height - 1)\n",
    "    p_within = np.logical_and(\n",
    "        np.logical_and(pw_valid_raw >= 0, pw_valid_raw < width),\n",
    "        np.logical_and(ph_valid_raw >= 0, ph_valid_raw < height))\n",
    "\n",
    "    depth_tgt_valid = depth_tgt[ph_valid, pw_valid]\n",
    "\n",
    "    p_within = np.logical_and(p_within, np.abs(depth_tgt_valid - depth_proj_valid) < thresh)\n",
    "    p_valid = np.abs(depth_tgt_valid) > 1e-10\n",
    "    fg_points = valid_points[np.logical_and(p_within, p_valid)]\n",
    "    visible[fg_points] = 1\n",
    "    visible = visible.reshape(depth_src.shape[:2])\n",
    "    w_ori, h_ori = np.meshgrid(np.linspace(0, width - 1, width), np.linspace(0, height - 1, height))\n",
    "    if standard_rep:\n",
    "        flow = np.dstack([pw.reshape(depth_src.shape[:2]) - w_ori, ph.reshape(depth_src.shape[:2]) - h_ori])\n",
    "    else:\n",
    "        # depleted version, only used in old code\n",
    "        flow = np.dstack([ph.reshape(depth_src.shape[:2]) - h_ori, pw.reshape(depth_src.shape[:2]) - w_ori])\n",
    "    flow[np.dstack([visible, visible]) != 1] = 0\n",
    "    assert np.isnan(flow).sum() == 0\n",
    "    X_valid = np.array([c[np.where(visible.flatten())] for c in X])\n",
    "    return flow, visible, X_valid\n",
    "\n",
    "def run (idx1,idx2):\n",
    "     # only for debug\n",
    "    import cv2\n",
    "    import scipy.io as scio\n",
    "    obj = '005_tomato_soup_can'\n",
    "    model = '/media/scratch1/jonfrey/datasets/YCB_Video_Dataset/models'\n",
    "    base = '/media/scratch1/jonfrey/datasets/YCB_Video_Dataset/data/0003'\n",
    "\n",
    "    im_src = cv2.imread(f'{base}/{idx1}-color.png',cv2.IMREAD_COLOR)\n",
    "    im_tgt = cv2.imread(f'{base}/{idx2}-color.png', cv2.IMREAD_COLOR)\n",
    "    print(f'{base}/{idx1}_depth.png')\n",
    "    depth_src = ( cv2.imread(f'{base}/{idx1}-depth.png',cv2.IMREAD_UNCHANGED).astype(np.float32) / 10000 )\n",
    "    depth_tgt = ( cv2.imread(f'{base}/{idx2}-depth.png',cv2.IMREAD_UNCHANGED).astype(np.float32) / 10000 )\n",
    "\n",
    "    pose_src = scio.loadmat(f'{base}/{idx1}-meta.mat')['poses'][:, :, 0]\n",
    "    pose_tgt = scio.loadmat(f'{base}/{idx2}-meta.mat')['poses'][:, :, 0]\n",
    "\n",
    "    if True:\n",
    "        from lib.pair_matching import RT_transform\n",
    "\n",
    "        print(\"trans: {}\".format(pose_src[:, -1]))\n",
    "        print(\"euler: {}\".format(RT_transform.mat2euler(pose_src[:, :3])))\n",
    "\n",
    "    K = np.array([[1066.778, 0, 312.9869], [0, 1067.487, 241.3109], [0, 0, 1]])\n",
    "    t = time()\n",
    "    flow, visible,X_valid = calc_flow(depth_src, pose_src, pose_tgt, K, depth_tgt)\n",
    "    print(time() - t)\n",
    "    a = np.where(np.squeeze(visible[:, :]))\n",
    "    print(a[0][:20])\n",
    "    print(a[1][:20])\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    fig.add_subplot(2, 4, 1)\n",
    "    plt.imshow(im_src)\n",
    "    fig.add_subplot(2, 4, 2)\n",
    "    plt.imshow(im_tgt)\n",
    "    fig.add_subplot(2, 4, 3)\n",
    "    plt.imshow(depth_src)\n",
    "    fig.add_subplot(2, 4, 4)\n",
    "    plt.imshow(depth_tgt)\n",
    "\n",
    "    fig.add_subplot(2, 4, 5)\n",
    "    height = depth_src.shape[0]\n",
    "    width = depth_src.shape[1]\n",
    "    img_tgt = np.zeros((height, width, 3), np.uint8)\n",
    "    img_src = np.zeros((height, width, 3), np.uint8)\n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            if visible[h, w]:\n",
    "                cur_flow = flow[h, w, :]\n",
    "                img_src = cv2.line(\n",
    "                    img_src,\n",
    "                    (np.round(w).astype(int), np.round(h).astype(int)),\n",
    "                    (np.round(w).astype(int), np.round(h).astype(int)),\n",
    "                    (255, h * 255 / height, w * 255 / width),\n",
    "                    5)\n",
    "                img_tgt = cv2.line(\n",
    "                    img_tgt,\n",
    "                    (np.round(w + cur_flow[1]).astype(int), np.round(h + cur_flow[0]).astype(int)),\n",
    "                    (np.round(w + cur_flow[1]).astype(int), np.round(h + cur_flow[0]).astype(int)),\n",
    "                    (255, h * 255 / height, w * 255 / width),\n",
    "                    5)\n",
    "    plt.imshow(img_src)\n",
    "    fig.add_subplot(2, 4, 6)\n",
    "    plt.imshow(img_tgt)\n",
    "    plt.show()\n",
    "    \n",
    "    fig2 = plt.figure()\n",
    "    plt.imshow(img_src)\n",
    "    plt.show()\n",
    "    fig3 = plt.figure()\n",
    "    plt.imshow(img_tgt)\n",
    "    plt.show()\n",
    "    print(depth_tgt)\n",
    "    return img_src, img_tgt\n",
    "if __name__ == \"__main__\":\n",
    "    img_src1, img_tgt1 = run(idx1 = \"000001\", idx2 = \"000100\")\n",
    "    img_src2, img_tgt2 =run(idx1 = \"000001\", idx2 = \"000002\")\n",
    "    fig = plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(img_tgt1)\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(img_tgt2)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'osmesa' # 'egl'\n",
    "\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "#print(pyglet)\n",
    "# from random import choice\n",
    "# import random\n",
    "# import PIL\n",
    "from math import pi\n",
    "from PIL import Image\n",
    "# import imageio\n",
    "import copy\n",
    "# from scipy.spatial.transform import Rotation as R\n",
    "import matplotlib.pyplot as plt\n",
    "# import gc\n",
    "import time\n",
    "import cv2\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = '005_tomato_soup_can'\n",
    "model = '/media/scratch1/jonfrey/datasets/YCB_Video_Dataset/models'\n",
    "base = '/media/scratch1/jonfrey/datasets/YCB_Video_Dataset/data/0003'\n",
    "idx1 = '000010'\n",
    "im_src = cv2.imread(f'{base}/{idx1}-color.png',cv2.IMREAD_COLOR)\n",
    "depth_src = ( cv2.imread(f'{base}/{idx1}-depth.png',cv2.IMREAD_UNCHANGED).astype(np.float32) / 10000 )\n",
    "pose_src = scio.loadmat(f'{base}/{idx1}-meta.mat')['poses'][:, :, 0]\n",
    "\n",
    "# trimeshes = [trimesh.load(x + '/geometry.ply') for x in seq_paths]\n",
    "# meshs = [pyrender.Mesh.from_trimesh(\n",
    "# trimesh.load(x + '/geometry.ply')) for x in seq_paths]\n",
    "# vertices, indices = data.objload(f'{model}/{obj}/textured.obj', rescale=False)\n",
    "# texture_map = data.load(f'{model_folder}/texture_map.png')[::-1, :, :])\n",
    "\n",
    "\n",
    "bill_trimesh = trimesh.load(f'{model}/{obj}/textured.obj')\n",
    "mesh = pyrender.Mesh.from_trimesh(bill_trimesh, smooth=False, wireframe=True)\n",
    "\n",
    "scene = pyrender.Scene()\n",
    "scene.add(mesh)\n",
    "ren = pyrender.OffscreenRenderer(600, 600, point_size=5)\n",
    "\n",
    "#pyrender.Viewer(scene, use_raymond_lighting=True)\n",
    "color, depth = ren.render(scene)\n",
    "                          \n",
    "#     print(\"render_time:\", time.time() - t_render)\n",
    "#     # Show the images\n",
    "#     t_render = time.time()\n",
    "#     plt.axis('off')\n",
    "plt.imshow(color)  # imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     outpath = path_seq + '/%i.png' % k\n",
    "#     outpathd = path_seq + '/%id.png' % k\n",
    "#     outpathmeta = path_seq + '/%i_meta.npy' % k\n",
    "\n",
    "# plt.figure()\n",
    "# plt.subplot(1, 1, 1)\n",
    "\n",
    "# st = time.time()\n",
    "\n",
    "# scene = pyrender.Scene(bg_color=(0, 0, 0, 255))\n",
    "# scene.clear()\n",
    "# ren = pyrender.OffscreenRenderer(600, 600, point_size=5)\n",
    "# pose = np.eye(4)\n",
    "# pose[0, 3] = x_range[x_idx_obj[j]]\n",
    "# pose[1, 3] = y_range[y_idx_obj[j]]\n",
    "# pose[2, 3] = z_range[z_idx_obj[j]]\n",
    "# pose[:3, :3] = r.as_matrix()\n",
    "# node_list.append(scene.add(meshs[idx], pose=pose))\n",
    "# obj_node = scene.add(meshs[obj_idx], pose=pose)\n",
    "\n",
    "# # Set camera and lighting\n",
    "# cx = 300\n",
    "# cy = 300\n",
    "# fx = 1066.778\n",
    "# fy = 1067.487\n",
    "# camera = pyrender.IntrinsicsCamera(\n",
    "#     fx, fy, cx, cy, znear=0.00001, zfar=10000.0, name=None)\n",
    "# camera_pose = np.array([\n",
    "#     [1, 0, 0, 0],\n",
    "#     [0, -1, 0.0, 0],\n",
    "#     [0.0, 0, -1, 0],\n",
    "#     [0.0, 0.0, 0.0, 1.0],\n",
    "# ])\n",
    "# light = pyrender.SpotLight(color=np.ones(3), intensity=35.0,\n",
    "#                            innerConeAngle=np.pi / 10.0)\n",
    "# scene.add(light, pose=camera_pose)\n",
    "# st2 = time.time()\n",
    "# scene.add(camera, pose=camera_pose)\n",
    "\n",
    "# k = 0\n",
    "\n",
    "#     # scene = copy.copy(scene_store)\n",
    "#     scene.set_pose(obj_node, pose=pose)\n",
    "\n",
    "#     pose[:3, 3] += obj_v\n",
    "\n",
    "#     # Render the scen\n",
    "#     t_render = time.time()\n",
    "#     color, depth = ren.render(scene)\n",
    "#     print(\"render_time:\", time.time() - t_render)\n",
    "#     # Show the images\n",
    "#     t_render = time.time()\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(color)  # imshow\n",
    "\n",
    "#     outpath = path_seq + '/%i.png' % k\n",
    "#     outpathd = path_seq + '/%id.png' % k\n",
    "#     outpathmeta = path_seq + '/%i_meta.npy' % k\n",
    "# ren.delete()\n",
    "\n",
    "if save:\n",
    "\n",
    "            # magic 45 degree rotation.\n",
    "            pose2 = np.eye(4)\n",
    "            pose2[:3, :3] = R.from_euler('z', -45, degrees=True).as_matrix()\n",
    "\n",
    "            meta = {'pose_se3': pose,\n",
    "                    'cx': cx,\n",
    "                    'cy': cy,\n",
    "                    'fx': fx,\n",
    "                    'fy': fy}\n",
    "            np.save(outpathmeta, meta)\n",
    "\n",
    "            img = Image.fromarray(color)\n",
    "            img = img.convert(\"RGBA\")\n",
    "            datas = img.getdata()\n",
    "\n",
    "            newData = []\n",
    "\n",
    "            # make white pixles transparent\n",
    "            for item in datas:\n",
    "                if item[0] == 0 and item[1] == 255 and item[2] == 0:\n",
    "                    newData.append((255, 255, 255, 0))\n",
    "                else:\n",
    "                    newData.append(item)\n",
    "            img.putdata(newData)\n",
    "            img.save(outpath, \"PNG\")\n",
    "            # converte depth into 1*mm -> max range 6 meter\n",
    "            depth_store = np.array(depth * 1000, dtype=np.uint16)\n",
    "            depth_store[depth_store == 0] = 65536\n",
    "\n",
    "            imageio.imwrite(outpathd, depth_store)\n",
    "        else:\n",
    "            print(\"show\")\n",
    "            plt.axis('on')\n",
    "            plt.show()\n",
    "        print(\"store_time:\", time.time() - t_render)\n",
    "\n",
    "        k += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track",
   "language": "python",
   "name": "track"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
