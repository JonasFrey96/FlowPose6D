{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch \n",
    "print('START')\n",
    "os.chdir('/home/jonfrey/PLR3')\n",
    "sys.path.insert(0, os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd() + '/src'))\n",
    "sys.path.append(os.path.join(os.getcwd() + '/lib'))\n",
    "\n",
    "import loaders_v2\n",
    "from loaders_v2 import GenericDataset\n",
    "from rotations import * \n",
    "\n",
    "exp_cfg_path = '/home/jonfrey/PLR3/yaml/exp/exp_ws_deepim_debug_natrix.yml'\n",
    "env_cfg_path = '/home/jonfrey/PLR3/yaml/env/env_natrix_jonas.yml'\n",
    "\n",
    "def load_from_file(p):\n",
    "    if os.path.isfile(p):\n",
    "        with open(p, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return data\n",
    "\n",
    "exp = load_from_file(exp_cfg_path)\n",
    "env = load_from_file(env_cfg_path)\n",
    "\n",
    "dataset_train = GenericDataset(\n",
    "    cfg_d=exp['d_train'],\n",
    "    cfg_env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import copy\n",
    "import k3d\n",
    "\n",
    "class Drawer():\n",
    "    def __init__(self):\n",
    "        self.im_in_plot = 0\n",
    "        self.data = []\n",
    "    def disp_img_1d(self,img,hold=False):\n",
    "        self.data.append(img)\n",
    "        \n",
    "        if not hold:\n",
    "            fig = plt.figure(figsize=(6*2*len(self.data),7))\n",
    "            ax = []\n",
    "            for j,a in enumerate(self.data):\n",
    "                ax.append( fig.add_subplot(1,len(self.data), j+1)  )\n",
    "                \n",
    "                ax[-1].get_xaxis().set_visible(False)\n",
    "                ax[-1].get_yaxis().set_visible(False)\n",
    "                pos = ax[-1].imshow( a, cmap='Blues' )\n",
    "                fig.colorbar(pos, ax=ax[-1])\n",
    "            plt.show()\n",
    "            self.data = []\n",
    "            self.ax = []\n",
    "            print('SHOW')\n",
    "            \n",
    "def plot_two_pcd_line(x, y, point_size=0.005, c1='g', c2='r'):\n",
    "    if c1 == 'b':\n",
    "        k = 245\n",
    "    elif c1 == 'g':\n",
    "        k = 25811000\n",
    "    elif c1 == 'r':\n",
    "        k = 11801000\n",
    "    elif c1 == 'black':\n",
    "        k = 2580\n",
    "    else:\n",
    "        k = 2580\n",
    "\n",
    "    if c2 == 'b':\n",
    "        k2 = 245\n",
    "    elif c2 == 'g':\n",
    "        k2 = 25811000\n",
    "    elif c2 == 'r':\n",
    "        k2 = 11801000\n",
    "    elif c2 == 'black':\n",
    "        k2 = 2580\n",
    "    else:\n",
    "        k2 = 2580\n",
    "\n",
    "    col1 = np.ones(x.shape[0]) * k\n",
    "    col2 = np.ones(y.shape[0]) * k2\n",
    "    plot = k3d.plot(name='points')\n",
    "    plt_points = k3d.points(x, col1.astype(np.uint32), point_size=point_size)\n",
    "    plot += plt_points\n",
    "    plt_points = k3d.points(y, col2.astype(np.uint32), point_size=point_size)\n",
    "    plot += plt_points\n",
    "    for i in range(min(100,x.shape[0]) ):\n",
    "        plot += k3d.line([x[i],y[i]],shader='mesh', width=0.0005, color=0xff0000)\n",
    "    \n",
    "    plt_points.shader = '3d'\n",
    "    plot.display()\n",
    "    \n",
    "draw = Drawer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "for j in range(0,1):\n",
    "    i = np.random.randint(0,10000)\n",
    "    batch = dataset_train[i][0] #bann 10450\n",
    "    points, choose, img, target, model_points, idx = batch[0:6]\n",
    "    depth_img, label_img, img_orig, cam = batch[6:10]\n",
    "    gt_rot_wxyz, gt_trans, unique_desig = batch[10:13]\n",
    "\n",
    "    real_img, render_img, real_d, render_d, gt_label_cropped = batch[13:18]\n",
    "    pred_rot_wxyz, pred_trans, pred_points, h_render,h_real, render_img_original = batch[18:24]\n",
    "    u_map, v_map, flow_mask, bb = batch[24:]\n",
    "    real_tl, real_br, ren_tl, ren_br = bb\n",
    "    from visu import Visualizer\n",
    "    visualizer = Visualizer('/home/jonfrey/Debug')\n",
    "    visualizer.plot_corrospondence('tag', 2, u_map, v_map, flow_mask, real_img, render_img, store=False, jupyter=True, coloful = True)\n",
    "\n",
    "#     draw = Drawer()\n",
    "#     draw.disp_img_1d( u_map, True)\n",
    "#     draw.disp_img_1d( v_map, True)\n",
    "#     draw.disp_img_1d( flow_mask )\n",
    "#     # draw.disp_img_1d( gt_label_cropped )\n",
    "\n",
    "# #     c1[ int(b_real.tl[0]):int(b_real.br[0]), int(b_real.tl[1]):int(b_real.tl[1]+5) ] = 100000\n",
    "# #     c1[ int(b_real.tl[0]):int(b_real.br[0]), int(b_real.br[1]):int(b_real.br[1]+5) ] = 100000\n",
    "#     img_orig [ int(b_real.tl[0]):int(b_real.br[0]), int(b_real.tl[1]):int(b_real.tl[1]+5),:] = torch.tensor( [0,255,0] )\n",
    "#     img_orig [ int(b_real.tl[0]):int(b_real.br[0]), int(b_real.br[1]):int(b_real.br[1]+5),:] = torch.tensor( [0,255,0] )\n",
    "#     print(b_ren.br, b_ren.tl)\n",
    "    \n",
    "#     render_img_original [ int(b_ren.tl[0]):int(b_ren.br[0]), int(b_ren.tl[1]):int(b_ren.tl[1]+5),:] = torch.tensor( [0,255,0] )\n",
    "#     render_img_original [ int(b_ren.tl[0]):int(b_ren.br[0]), int(b_ren.br[1]):int(b_ren.br[1]+5),:] = torch.tensor( [0,255,0] )\n",
    "\n",
    "#     display( Image.fromarray(np.uint8(img_orig.numpy())) )\n",
    "#     display( Image.fromarray(np.uint8(render_img_original.numpy())) )\n",
    "print(time.time()-st)\n",
    "bb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_im import flow_to_trafo\n",
    "\n",
    "K_ren = torch.from_numpy( dataset_train._backend.get_camera('data_syn/000001', K=True) )\n",
    "K_real =  torch.from_numpy(dataset_train._backend.get_camera('data_syn/000001', K=True) )\n",
    "\n",
    "P_real, P_ren, P_real_trafo, T_res = flow_to_trafo(\n",
    "                            real_br, real_tl,ren_br, ren_tl, \n",
    "                            flow_mask, \n",
    "                            u_map, v_map, \n",
    "                            K_real, K_ren, \n",
    "                            real_d[0], render_d[0], \n",
    "                            h_real, h_render)\n",
    "\n",
    "print(f\"GT Trans: {gt_trans} \")\n",
    "print(f\"Pred Trans: {pred_trans} \")\n",
    "print(f\"Delta1 Trans: {pred_trans- gt_trans} \")\n",
    "print(f\"Delta2 Trans: {- pred_trans+ gt_trans} \")\n",
    "print(f\"Trafo: {(T_res)[:3,3]} \")\n",
    "\n",
    "print(f\"Trafo Inverse: {torch.inverse(T_res)[:3,3]} \")\n",
    "print(f\"GT Offset {h_real[:3,3] - pred_trans}, Estimated given GT corrospondence {torch.inverse(T_res)[:3,3]}\" )\n",
    "\n",
    "print(f\"Do they match {(T_res)[:3,3]} {- pred_trans+ gt_trans} ???\")\n",
    "\n",
    "sam = max(1,int(P_real.shape[0]/100))\n",
    "plot_two_pcd_line(P_real.numpy()[::sam,:], P_ren.numpy()[::sam,:])\n",
    "\n",
    "# plot_two_pcd_line(P_real_trafo.numpy()[::sam,:], P_ren.numpy()[::sam,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = gt_trans - pred_trans.numpy()\n",
    "sol\n",
    "\n",
    "T_res\n",
    "torch.inverse(T_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten = torch.rand((480,640))\n",
    "mh = 480\n",
    "mw = 640\n",
    "\n",
    "h = torch.arange(1,50,1).type(torch.long)\n",
    "w = torch.arange(51,100,1).type(torch.long)\n",
    "\n",
    "index = h*mw + w\n",
    "\n",
    "out_ten = ten.flatten()\n",
    "print(out_ten.shape)\n",
    "\n",
    "print(\"Out\", out_ten[index][:3]) \n",
    "\n",
    "\n",
    "for i in range(h.shape[0]):\n",
    "    print( ten[h[i],w[i]])\n",
    "    if i > 3:\n",
    "        break\n",
    "    \n",
    "#ind = torch.cat([ind1[:,None],ind2[:,None]],dim=1)\n",
    "#print(ind)\n",
    "\n",
    "#ten[ind]\n",
    "#torch.index_select(ten, (0,1) ,ind)\n",
    "# , real_tl,ren_br, ren_tl, \n",
    "#                             flow_mask, \n",
    "#                             u_map, v_map, \n",
    "#                             K_real, K_ren, \n",
    "#                             real_d[0], render_d["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the vectors in the \"Current Object Center Frame\" for rendered and real \n",
    "from visu import plot_pcd\n",
    "from visu import plot_two_pcd\n",
    "import k3d\n",
    "from visu import plot_two_pcd\n",
    "import copy\n",
    "    \n",
    "K_ren = dataset_train._backend.get_camera('data_syn/000001', K=True)\n",
    "K_real = dataset_train._backend.get_camera('data_syn/000001', K=True)\n",
    "\n",
    "print(real_d.shape)\n",
    "\n",
    "P_real, P_ren, P_real_trafo, T_res = calculate_relative_pose(real_br, \n",
    "                            real_tl, \n",
    "                            ren_br, \n",
    "                            ren_tl, \n",
    "                            flow_mask, \n",
    "                            u_map, \n",
    "                            v_map, \n",
    "                            K_real, \n",
    "                            K_ren, \n",
    "                            real_d[0], \n",
    "                            render_d[0], \n",
    "                            h_real, \n",
    "                            h_render)\n",
    "    \n",
    "plot_two_pcd_line(P_real[::500,:], P_ren[::500,:])\n",
    "plot_two_pcd_line(P_real_trafo[::500,:], P_ren[::500,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # render_img\n",
    "# # \n",
    "# a = render_d[0].numpy()\n",
    "# m = np.max( a )\n",
    "\n",
    "# b = (a/  m) * 255 \n",
    "# #  print(b[None,:,:].repeat(3,0).shape)\n",
    "# # c = b[None,:,:].repeat(3,0)\n",
    "# img = Image.fromarray( b )\n",
    "# display(img.convert(\"L\") )\n",
    "# draw.disp_img_1d(render_d[0].numpy())\n",
    "# draw.disp_img_1d(real_d[0].numpy())\n",
    "# visualizer.plot_corrospondence('tag', 2, u_map, v_map, flow_mask, real_img, render_img, store=False, jupyter=True, coloful = True)\n",
    "\n",
    "grid_h, grid_w = np.mgrid[0 :480:1 , 0:640:1]\n",
    "\n",
    "\n",
    "ren_pixels_c = np.stack( [grid_w[flow_mask] - v_map[flow_mask].numpy(), \n",
    "                        grid_h[flow_mask] - u_map[flow_mask].numpy()], axis=1 )\n",
    "img1 = copy.deepcopy( render_d[0].numpy() )\n",
    "draw.disp_img_1d(img1, True)\n",
    "ind = np.zeros( (480,640) )\n",
    "for i in range(ren_pixels_c.shape[0]):\n",
    "    ind[ int(  ren_pixels_c[i,1] ) , int( ren_pixels_c[i,0]) ] = 1\n",
    "ind2 = ind == 1\n",
    "img2 = copy.deepcopy( img1 )\n",
    "img2[ ind2 ] = 10000\n",
    "draw.disp_img_1d(img2)\n",
    "\n",
    "\n",
    "\n",
    "ren_pixels_c = np.stack( [grid_w[flow_mask], \n",
    "                        grid_h[flow_mask]], axis=1 )\n",
    "img1 = copy.deepcopy( real_d[0].numpy() )\n",
    "draw.disp_img_1d(img1, True)\n",
    "ind = np.zeros( (480,640) )\n",
    "for i in range(ren_pixels_c.shape[0]):\n",
    "    ind[ int(  ren_pixels_c[i,1] ) , int( ren_pixels_c[i,0]) ] = 1\n",
    "ind2 = ind == 1\n",
    "img2 = copy.deepcopy( img1 )\n",
    "img2[ ind2 ] = 40000\n",
    "draw.disp_img_1d(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visu import plot_two_pcd\n",
    "def filter_pcd( pcd, tol = 0.5):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        pcd : Nx3 np.float32\n",
    "    returns:\n",
    "        mask : NX3 np.bool \n",
    "    \"\"\"\n",
    "    m = np.mean(pcd, axis = 0)\n",
    "    comp = m[None,:].repeat(pcd.shape[0],0) + tol\n",
    "    mean_free = pcd-m[None,:].repeat(comp.shape[0],0)\n",
    "    mask = np.linalg.norm( mean_free,  axis= 1) > tol\n",
    "    # print( f'Invalid Points outside of tol {tol}, {np.sum( mask, axis=0)}')\n",
    "    \n",
    "    return mask[:,None].repeat(3,1) == False\n",
    "\n",
    "\n",
    "m_real = filter_pcd( P_real_in_center[::100,:] )\n",
    "m_ren = filter_pcd( P_ren_in_center[::100,:] )\n",
    "m_tot = m_real * m_ren\n",
    "# use the mask calculated for both\n",
    "\n",
    "\n",
    "\n",
    "# P_real_in = P_real_in_center[::100,:][m_tot[:,0]]\n",
    "# P_ren_in = P_ren_in_center[::100,:][m_tot[:,0]]\n",
    "\n",
    "plot_two_pcd(P_real_in, P_ren_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "print( torch.from_numpy(P_real_in)[None].shape)\n",
    "print( torch.from_numpy(P_ren_in).shape)\n",
    "T = solve_transform( torch.from_numpy(P_real_in)[None] , torch.from_numpy(P_ren_in) ) \n",
    "print('R.shape', T)\n",
    "# print('Inital Trans', pred_trans)\n",
    "# print('Gt', h_real)\n",
    "\n",
    "# T @ keypoints == gt_keypoints.\n",
    "    \n",
    "print('Delta:',  h_real[:3,3]- pred_trans.numpy())\n",
    "from visu import plot_two_pcd\n",
    "import copy\n",
    "\n",
    "P_h = np.ones( (P_ren_in.shape[0],4 ) )\n",
    "P_h[:,:3] = P_ren_in\n",
    "\n",
    "P_hr = np.ones( (P_real_in.shape[0],4 ) )\n",
    "P_hr[:,:3] = P_real_in\n",
    "\n",
    "P_real_trafo = (np.linalg.inv( T[0].numpy() ) @ copy.deepcopy(P_hr).T).T\n",
    "print(P_real_trafo)\n",
    "P_real_trafo = P_real_trafo[:,:3]\n",
    "plot_two_pcd_line(P_real_in, P_ren_in)\n",
    "plot_two_pcd_line(P_real_trafo, P_ren_in)\n",
    "\n",
    "# plot_two_pcd(P_real_trafo , P_ren_in)\n",
    "# plot_two_pcd(P_real_in, P_ren_in)\n",
    "\n",
    "# # plot_two_pcd(P_real_in_center[::100,:], P_ren_trafo[:,:3])\n",
    "# # plot_two_pcd(P_real_trafo[:,:3], P_ren_in_center[::100,:])\n",
    "# # plot_two_pcd(, point_size=0.005, c='r')\n",
    "# # Rrel=RjR−1i and Trel=−RrelTi+Tj.\n",
    "\n",
    "# h_rel = np.eye(4)\n",
    "# h_rel[:3,:3] = h_real[:3,:3] @ h_render[:3,:3].T\n",
    "# h_rel[:3, 3] = h_real[:3,3]- pred_trans.numpy()\n",
    "\n",
    "# print(h_rel)\n",
    "\n",
    "# P_h = np.ones( (P_ren_in.shape[0],4 ) )\n",
    "# P_h[:,:3] = P_ren_in\n",
    "# P_ren_gt = copy.deepcopy(P_h) @ h_rel\n",
    "\n",
    "\n",
    "# # Intermediate Goal get this relative position voteing working: Step1\n",
    "# # Get From Flow the Full Pose Estimate of the Obejct\n",
    "# # Throw the ADD-S at it !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cmap = plt.cm.get_cmap('gist_rainbow', 20)\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "import random\n",
    "print(random.choice(cmaplist)[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track_latest",
   "language": "python",
   "name": "track_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
