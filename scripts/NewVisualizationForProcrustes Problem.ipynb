{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Finished loading meshes 0.04542970657348633\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch \n",
    "print('START')\n",
    "os.chdir('/home/jonfrey/PLR3')\n",
    "sys.path.insert(0, os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd() + '/src'))\n",
    "sys.path.append(os.path.join(os.getcwd() + '/lib'))\n",
    "\n",
    "import loaders_v2\n",
    "from loaders_v2 import GenericDataset\n",
    "from rotations import * \n",
    "\n",
    "exp_cfg_path = '/home/jonfrey/PLR3/yaml/exp/exp_ws_deepim_debug_natrix.yml'\n",
    "env_cfg_path = '/home/jonfrey/PLR3/yaml/env/env_natrix_jonas.yml'\n",
    "\n",
    "def load_from_file(p):\n",
    "    if os.path.isfile(p):\n",
    "        with open(p, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return data\n",
    "\n",
    "exp = load_from_file(exp_cfg_path)\n",
    "env = load_from_file(env_cfg_path)\n",
    "\n",
    "dataset_train = GenericDataset(\n",
    "    cfg_d=exp['d_train'],\n",
    "    cfg_env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "class Drawer():\n",
    "    def __init__(self):\n",
    "        self.im_in_plot = 0\n",
    "        self.data = []\n",
    "    def disp_img_1d(self,img,hold=False):\n",
    "        self.data.append(img)\n",
    "        \n",
    "        if not hold:\n",
    "            fig = plt.figure(figsize=(6*2*len(self.data),7))\n",
    "            ax = []\n",
    "            for j,a in enumerate(self.data):\n",
    "                ax.append( fig.add_subplot(1,len(self.data), j+1)  )\n",
    "                \n",
    "                ax[-1].get_xaxis().set_visible(False)\n",
    "                ax[-1].get_yaxis().set_visible(False)\n",
    "                pos = ax[-1].imshow( a, cmap='Blues' )\n",
    "                fig.colorbar(pos, ax=ax[-1])\n",
    "            plt.show()\n",
    "            self.data = []\n",
    "            self.ax = []\n",
    "            print('SHOW')\n",
    "draw = Drawer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonfrey/PLR3/src/helper/bounding_box.py:269: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  masked_idx = (d != 0).nonzero()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8038341999053955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([114., -30.], dtype=torch.float64),\n",
       " tensor([471., 446.], dtype=torch.float64),\n",
       " tensor([27., 13.]),\n",
       " tensor([493., 633.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "for j in range(0,1):\n",
    "    i = np.random.randint(0,10000)\n",
    "    batch = dataset_train[i][0] #bann 10450\n",
    "    points, choose, img, target, model_points, idx = batch[0:6]\n",
    "    depth_img, label_img, img_orig, cam = batch[6:10]\n",
    "    gt_rot_wxyz, gt_trans, unique_desig = batch[10:13]\n",
    "\n",
    "    real_img, render_img, real_d, render_d, gt_label_cropped = batch[13:18]\n",
    "    pred_rot_wxyz, pred_trans, pred_points, h_render,h_real, render_img_original = batch[18:24]\n",
    "    u_map, v_map, flow_mask, bb = batch[24:]\n",
    "    real_tl, real_br, ren_tl, ren_br = bb\n",
    "#     from visu import Visualizer\n",
    "#     visualizer = Visualizer('/home/jonfrey/Debug')\n",
    "#     visualizer.plot_corrospondence('tag', 2, u_map, v_map, flow_mask, real_img, render_img, store=False, jupyter=True)\n",
    "\n",
    "#     draw = Drawer()\n",
    "#     draw.disp_img_1d( u_map, True)\n",
    "#     draw.disp_img_1d( v_map, True)\n",
    "#     draw.disp_img_1d( flow_mask )\n",
    "#     # draw.disp_img_1d( gt_label_cropped )\n",
    "\n",
    "# #     c1[ int(b_real.tl[0]):int(b_real.br[0]), int(b_real.tl[1]):int(b_real.tl[1]+5) ] = 100000\n",
    "# #     c1[ int(b_real.tl[0]):int(b_real.br[0]), int(b_real.br[1]):int(b_real.br[1]+5) ] = 100000\n",
    "#     img_orig [ int(b_real.tl[0]):int(b_real.br[0]), int(b_real.tl[1]):int(b_real.tl[1]+5),:] = torch.tensor( [0,255,0] )\n",
    "#     img_orig [ int(b_real.tl[0]):int(b_real.br[0]), int(b_real.br[1]):int(b_real.br[1]+5),:] = torch.tensor( [0,255,0] )\n",
    "#     print(b_ren.br, b_ren.tl)\n",
    "    \n",
    "#     render_img_original [ int(b_ren.tl[0]):int(b_ren.br[0]), int(b_ren.tl[1]):int(b_ren.tl[1]+5),:] = torch.tensor( [0,255,0] )\n",
    "#     render_img_original [ int(b_ren.tl[0]):int(b_ren.br[0]), int(b_ren.br[1]):int(b_ren.br[1]+5),:] = torch.tensor( [0,255,0] )\n",
    "\n",
    "#     display( Image.fromarray(np.uint8(img_orig.numpy())) )\n",
    "#     display( Image.fromarray(np.uint8(render_img_original.numpy())) )\n",
    "print(time.time()-st)\n",
    "bb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77539,) [136.3125 136.3125 136.3125 ... 447.2    447.2    447.2   ] [1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4251fb36e0824896b228b4398c618d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd6e1ca700344869dfac64599b1f123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e482fe1e53241a688cb657cc765454a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5f2f1e4a2c4237ab9529c904cdb781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What we gonna do: \n",
    "# 1. Given the Depth Map of the Real Image calculate the PCD machting disparity pixels. \n",
    "# 2. Given the Depth Map of the Render Image calculate the PCD for the rendered Image. \n",
    "\n",
    "# Visualize the vectors in the \"Current Object Center Frame\" for rendered and real \n",
    "from visu import plot_pcd\n",
    "\n",
    "\n",
    "# real_d[0][flow_mask]\n",
    "a = float((real_br[0]-real_tl[0])/480)\n",
    "b = float((real_br[1]-real_tl[1])/640)\n",
    "grid_real_h, grid_real_w = np.mgrid[int(real_tl[0]) :int(real_br[0]):a , int(real_tl[1]) :int(real_br[1]):b]\n",
    "\n",
    "a = float((ren_br[0]-ren_tl[0])/480)\n",
    "b = float((ren_br[1]-ren_tl[1])/640)\n",
    "grid_ren_h, grid_ren_w = np.mgrid[int(ren_tl[0]) :int(ren_br[0]):a , int(ren_tl[1]) :int(ren_br[1]):b]\n",
    "\n",
    "\n",
    "print(grid_real_w[flow_mask].shape, grid_real_h[flow_mask], np.ones(grid_real_h.shape)[flow_mask])\n",
    "\n",
    "cam_scale = 10000\n",
    "\n",
    "real_pixels = np.stack( [grid_real_w[flow_mask], grid_real_h[flow_mask], np.ones(grid_real_h.shape)[flow_mask]], axis=1 )\n",
    "K = np.array( [[int(cam[2]),0,int(cam[0])],[0,int(cam[3]),int(cam[1])],[0,0,1]] )\n",
    "K_inv = np.linalg.inv(K)\n",
    "\n",
    "P_real = K_inv @ real_pixels.T \n",
    "P_real = P_real * real_d[0][flow_mask].numpy() / cam_scale\n",
    "\n",
    "\n",
    "K_ren = dataset_train._backend.get_camera('data_syn/000001', K=True)\n",
    "K_ren_inv = np.linalg.inv(K_ren)\n",
    "ren_pixels = np.stack( [grid_ren_w[flow_mask]+v_map[flow_mask].numpy(), \n",
    "                        grid_ren_h[flow_mask]+u_map[flow_mask].numpy(),\n",
    "                        np.ones(grid_ren_h.shape)[flow_mask]], \n",
    "                        axis=1 )\n",
    "\n",
    "P_ren = K_ren_inv @ ren_pixels.T \n",
    "P_ren = P_ren * render_d[0][flow_mask].numpy() / cam_scale\n",
    "\n",
    "P_real = P_real.T\n",
    "P_ren = P_ren.T\n",
    "plot_pcd(P_real[::100,:], point_size=0.005, c='g')\n",
    "plot_pcd(P_ren[::100,:], point_size=0.005, c='g')\n",
    "\n",
    "\n",
    "\n",
    "P_real_in_center = P_real - h_real[:3,3].numpy()\n",
    "P_ren_in_center = P_ren - h_render[:3,3].numpy()\n",
    "\n",
    "\n",
    "plot_pcd(P_real_in_center[::100,:], point_size=0.005, c='r')\n",
    "plot_pcd(P_ren_in_center[::100,:], point_size=0.005, c='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10870237, -0.0889602 ,  0.90670361],\n",
       "       [-0.10806975, -0.08896019,  0.90670352],\n",
       "       [-0.10743715, -0.0889602 ,  0.90670361],\n",
       "       ...,\n",
       "       [-0.06281516,  0.17085785,  0.88411895],\n",
       "       [-0.0622506 ,  0.17100151,  0.8848623 ],\n",
       "       [-0.061685  ,  0.17114514,  0.88560557]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9930.)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real_d[0][flow_mask]\n",
    "torch.max( render_d[0][flow_mask] )\n",
    "torch.max( real_d[0][flow_mask] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track_latest",
   "language": "python",
   "name": "track_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
